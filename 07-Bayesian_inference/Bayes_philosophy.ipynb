{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian inference: Basics\n",
    "\n",
    "This notebook discusses more extensively some concepts mentioned in [Bayes_basics_short.ipynb](Bayes_basics_short.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Frequentist vs Bayesian Approaches\n",
    "\n",
    "Both the model fitting and model selection problems can be approached from either a *frequentist* or a *Bayesian* standpoint. \n",
    "Fundamentally, the difference between these lies in the **definition of probability** that they use:\n",
    "\n",
    "- **A frequentist probability is a measure *long-run frequency* of (real or imagined) repeated trials.** Among other things, this generally means that observed data can be described probabilistically (you can repeat the experiment and get a different realization) while model parameters are fixed, and cannot be described probabilistically (the universe remains the same no matter how many times you observe it). \n",
    "\n",
    "- **A Bayesian probability is a *quantification of belief*.** Among other things, this generally means that observed data are treated as fixed (you know exactly what values you measured) while model parameters – including the \"true\" values of the data reflected by noisy measurements – are treated probabilistically (your degree of knowledge about the universe changes as you gather more data).\n",
    "\n",
    "\n",
    "**Example**: The measurement of the flux of a star.\n",
    "\n",
    "- For frequentists, **probability** only has meaning in terms of a **limiting case of repeated measurements**. That is, if I measure the photon flux F from a given star (we'll assume for now that the star's flux does not vary with time), then measure it again, then again, and so on, each time I will get a slightly different answer due to the statistical error of my measuring device. In the limit of a large number of measurements, the frequency of any given value indicates the probability of measuring that value. For frequentists probabilities are fundamentally related to **frequencies of events**. This means, for example, that in a strict frequentist view, it is *meaningless* to talk about the probability of the true flux of the star: the true flux is (by definition) a single fixed value, and to talk about a frequency distribution for a fixed value is nonsense. To some extent, the frequentists approach more the world like Platon: there is a \"true\" model of the world, with fixed parameters that we try to grasp through experiments. \n",
    "\n",
    "- For Bayesians, the concept of probability is extended to cover degrees of certainty about statements. Say a Bayesian claims to measure the flux F of a star with some probability P(F): that probability can certainly be estimated from frequencies in the limit of a large number of repeated experiments, but this is not fundamental. The probability is a statement of my knowledge of what the measurement result will be. For Bayesians, probabilities are **fundamentally related to our own knowledge about an event**. This means, for example, that in a Bayesian view, we can meaningfully talk about the probability that the true flux of a star lies in a given range. That probability codifies our knowledge of the value based on prior information and/or available data. If we want to oppose this view to the \"Platonician one\", we could say that our model could be disconnected from the \"ground truth\" (provided this means anything), but this model is our most plausible representation of the world that we observe (it can in fact also be a heuristic or phenomenological model, with indirect connection to the physical process). Hence, our parameters may have uncertainties which reflect our ability to reproduce the data in the framework of our model. There is therefore no arm to speak of probability of model parameters. \n",
    "\n",
    "In summary: \n",
    "\n",
    "- *Frequentist inference*: estimating an error on a parameter means: \"how much would the parameter change if I had other data\". It is more a platonician view of the world: there is a true world defined by parameters and fixed values associated to the models. By gathering observations we approach on the long run the true parameter values of the model (supposed to be perfect but unaccessible). Indirectly, it also implies that the model has to be \"a correct representation of the truth\". \n",
    "- *Bayesian inference*: estimating an error on a parameter really means \"deriving a parameter and uncertainties on it\", something a frequentist cannot say as it strictly does not make sense (there is only one true value of a parameter that he tries to estimate and this does not make sense to speak of an uncertainty on a true value). For that purpose, Bayesian inference uses posterior distribution of the parameters (given the data) $p({\\boldsymbol{\\theta}} \\mid D)$. Our model could be disconnected from the truth, but is our best representation of the world that we observe. Hence, our parameters may have uncertainties which reflect our ability to reproduce the data.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
